I was excited when Apple anounced HomePod's ability to detect its location within a room, and optimise performance based on the real-time location, but it didn't work as I expected.  

I have 3 HomePod Mini in my studyroom, and they can play simultaneously under the same Wi-fi, which create a very cost-efficient stereo sound environment. However, I often have to manually change the volume balance between 3 speakers, because any one of the speaker will be too loud when I'm close to it, and the rest 2 will sounds too weak and lose the sound field balance.  

I want to build a environment, of which user's position is tracked, and speakers automaically adjust the volume balance for best perfromance.  

I will use one of the listed sensor to monitor the reletive position of user.  
    -- UWB beacon and receiver.(Most likely). 
    -- Ultrasonic module array.  
    -- RGB/double RGB/ToF/IR camera.  
    -- Other methods to be explored.  
    -- Alternatively, use RIFD or physical buttons for preset senarios.  

I will also use atleast 3 speaker module linked with bluetooth modules for audio output. I may or may not use portable power supply for this project, for best demonstration.

If I were to use UWB, I will likely make a wearable accessory for localisation purpose. 


Why: Proactive behavior is required to keep the best user experience in a room with stereo sound system, causing an unsmooth experience.   

What: Have devices activly detecte and auto-adjust performance will optimise user experience.  

How: Set up sensor to define reletive position between speakers and users. Aloow speakers balance sounds between the stereo system for best experience.  
![project proposal sketch](https://user-images.githubusercontent.com/80315339/139079676-58a6cdd3-1a03-4488-9c22-7d850a6eebbf.jpg)
